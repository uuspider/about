---
layout: post
title: shell crawler
---
## 最简单的网络机器人
### ——命令行写爬虫

参考：[][ref1]{:target="_blank"}, [][ref2]{:target="_blank"}, [][ref3]{:target="_blank"}, [][ref4]{:target="_blank"}

[ref1]:
[ref2]:
[ref3]:
[ref4]:

<h2 id="top"></h2>

***

*   [前言](#preface) : [](#config) \| [](#user) \| [](#vi) \| [](#info) \| [帮助](#help)

***

# 前言

网络爬虫是一种网络机器人，

如果你正在学习linux，你需要这本书。

linux命令多如牛毛，如何能在最短时间内掌握最常用的命令行工具，是本书的任务之一。

如果你对大数据感兴趣，你需要这本书。

本书将教你如何在短时间内从互联网上获取数据样本，甚至实现自动化、长期跟踪数据变化。

如果你

# 第一章 部署环境

## 1.1 概述

本书主要工具都是基于命令行的，在linux和Mac OS中，都内置了终端，你可以使用组合键Ctrl+Shift+T启动终端。命令行是与图形用户界面完全不同的人机交互方式。对于习惯于用鼠标的同学来说，这似乎是一个挑战。实际上，命令行并非你想象中的那么高大上，也并不难掌握。本书使用的是Ubuntu 16.04，是GUN/Linux的一个发行版。

## 1.2 在命令行中生存

## 1.3 选择你的编辑器




# 第二章 第一个爬虫

# 第三章 强大的curl

# 第四章 了解一点http协议

# 第五章 过滤、排序

# 第六章 正则表达式

# 第七章 流程控制

## 7.1 条件语句

## 7.2 循环语句

## 7.3 选择语句



# 第章 文本处理


# 权限管理


# 连接数据库


# 可视化




# 数据处理


# 并行处理 

**[[TOP](#top)]**

****
