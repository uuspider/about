---
layout: post
title: Encoding & decoding chinese characters
---


## 数制转换

由于下文会用到二进制和十六进制的相互转换，这里先简单给出python中数制转换的方法。

|---:|---:|---:|:---|
|十六进制|->|十进制|`int('80',16)`|
|十进制|->|十六进制|`hex(128)`|
|二进制|->|十进制|`int('10000000',2)` |
|十进制|->|二进制|`bin(128)`|
|十六进制|->|二进制|`bint(int('80',16))`|
|二进制|->|十六进制|`hex(int('10000000',2))`|
|十六进制|->|二进制|`bin(int('80',16))`|

<br>

## ASCII

计算机以二进制的0和1来存储和处理所有信息，其中每一个0或1被称作一个位bit，用小写b表示；八个bit为一个字节byte，用大写B表示，1B=8b，一个字节有00000000-11111111共256种不同组合，ANSI (American National Standards Institute)将这些组合与英语字符、空格以及其它一些控制符号一一对应，形成了ASCII (American Standard Code for Information Interchange)字符集。ASCII收录了128个字符，它们的编码就是对应的二进制数00000000-01111111，可以发现ASCII只占用了一个字节的后面7位，最前面的1位都是0。

## MBCS

计算机技术传播到非英语国家后，ASCII就无法满足需求了。开始的时候，大家采用一个字节里将没有利用的0、1组合与一些字母和符号对应，形成了包括10000000-11111111的“扩展字符集”。但是，这显然无法满足需求，于是，计算机所到之处，每种语言都开始重新制定自己的字符集，由于单字节能表示的字符太少，这些字符集纷纷使用了多字节来表示字符，如GBxxx、BIGxxx等DBCS (Double Byte Charecter Set)等方案采用了两个字节，他们的规则是，如果第一个字节小于等于01111111，则仍然表示ASCII字符；而如果大于等于10000000，则跟下一个字节一起共16位表示一个字符，然后跳过下一个字节，继续往下判断。这些字符集被统称为MBCS(Multi-Byte Character Set)，IBM搞了一个Code Page，为这些字符集统一分配页码，GBK是第936页，因此GBK有时候也被记作CP936。MBCS不是某一种特定的字符集，而是字符集的集合，同时期流行起来的Microsoft Windows会根据计算机设定区域，调用不同的字符集，微软的程序员把他们这样的方案叫作ANSI，在简体中文Windows中，ANSI就是GBK。

GB2312字符集是1981年由中国发布的国家标准，采用两个大于等于10000000的字节连在一起表示一个字符，收录了6763个汉字以及拉丁字母、希腊字母、平假名、片假名、俄语西里尔字母等682个字符，GB2312还把ASCII里原有的数字、标点、字母按照自己的方案重新编成了两个字节即1xxxxxxx1xxxxxxx的0、1组合，形成了“全角”字符。

GB2312字符集仍然无法满足庞大的汉字字库的需求，于是，GBK字符集在兼容GB2312的基础上，将第二个字节里小于等于01111111的组合也利用起来，形成了“汉字内码扩展规范”，GBK中的K就是汉语拼音Kuo Zhan的意思。GBK收录21886个汉字和图形符号，包括GB2312中的全部字符，BIG5的全部汉字，以及其他汉字、部首、符号。GBK进一步扩展，将中国少数民族文字、日韩汉字、繁体汉字等等包括进来，形成了GB18030 - 2005《信息技术中文编码字符集》，GB18030字符集采用了一二四字节可变长度编码方式，单字节(0-127)与ASCII编码兼容，双字节兼容GB2312，四字节(129-254，48-57，129-254，48-57)。

## unicode

这些编码五花八门，给程序员带来了不小的麻烦。ISO (国际标谁化组织)决定从零开始，对所有字符进行重新编码，这就是UCS (Universal Multiple-Octet Coded Character Set)，习惯被称为unicode。UCS-2采用16位编码(UCS-4采用了32位编码)，即两个字节，对于一个字节就可以满足编码需求的英语文本来说，多出的空位造成存储空间的浪费，文件大小大了一倍。因此，unicode在很长一段时间都没有推广开。

字符集和编码是不同的概念，做个类比，“苹果”这种水果在汉语叫“苹果”，在英语里叫“apple”，这是对这种水果的不同“编码”，但指的却是同一种东西。

互联网流行后，UTF (UCS Transfer Format)作为unicode的实现方式开始普及，UTF-8每次传输8位，UTF-16每次传输16位。其中，广泛应用的是UTF-8，这是一种为传输而设计的编码方案。

UTF-8是一种长度变化的编码方式，使用1-4个字节表示一个字符。对于单字节的字符，字节的第一位设为0，后面7位就是该字符的unicode码，对于英语字母，UTF-8码和ASCII码相同；对于n个字节的符号(n>1)，第一个字节的前n位设为1，第n+1位设为0，后面字节的前两位一律设为10，其余空位为该字符的unicode码。

|unicode编码|UTF-8传输和储存方式|
|:---|:---|
|十六进制|二进制|
|0000 0000-0000 007F|0xxxxxxx|
|0000 0080-0000 07FF|110xxxxx 10xxxxxx|
|0000 0800-0000 FFFF|1110xxxx 10xxxxxx 10xxxxxx|
|0001 0000-0010 FFFF|11110xxx 10xxxxxx 10xxxxxx 10xxxxxx|


<br>

## 编码检测

在python中，可以使用chardet对字符串、文件进行编码检测。

    >>> import chardet
    >>> f = open('test.txt')
    >>> s = f.read()
    >>> f.close()
    >>> chardet.detect(s)
    
## 编码与解码

    >>> u = u'中文编码'
    >>> s = u.encode('UTF-8')
    >>> u2 = s.decode('UTF-8')
    >>> print repr(u)
    u'\u4e2d\u6587\u7f16\u7801'
    >>> print repr(s)
    '\xe4\xb8\xad\xe6\x96\x87\xe7\xbc\x96\xe7\xa0\x81'
    >>> print repr(u2)
    u'\u4e2d\u6587\u7f16\u7801'
    >>> print str(s)
    中文编码
    
注意，下面几种情况会报错：

    >>> s2 = u.decode('UTF-8') #对unicode解码是错误的
    >>> u2 = s.encode('UTF-8') #对字符串编码是错误的
    >>> print str(u) #对unicode解码是错误的

`str()`返回的是给程序员看的字符串，`repr()`返回的是给计算机看的编码。

如果一个文件是GBK编码，可以通过下面的方法转成UTF-8编码。

    >>> f = open('gbk.txt')
    >>> s = f.read()
    >>> f.close
    >>> u = s.decode('GBK')
    >>> f = open('gbk.txt', 'w')
    >>> s = u.encode('UTF-8')
    >>> f.write(s)
    >>> f.close
















