---
layout: post
title: Encoding & decoding chinese characters
---


## 数制转换

由于下文会用到二进制和十六进制的相互转换，这里先简单给出python中数制转换的方法。

|---:|---:|---:|:---|
|十六进制|->|十进制|`int('80',16)`|
|十进制|->|十六进制|`hex(128)`|
|二进制|->|十进制|`int('10000000',2)` |
|十进制|->|二进制|`bin(128)`|
|十六进制|->|二进制|`bin(int('80',16))`|
|二进制|->|十六进制|`hex(int('10000000',2))`|

<br>

## ASCII

计算机以二进制的0和1来存储和处理所有信息，其中每一个0或1被称作一个位bit，用小写b表示；八个bit为一个字节byte，用大写B表示，1B=8b，一个字节有0000 0000 - 1111 1111共256种不同组合，ANSI (American National Standards Institute)将这些组合与英语字符、空格以及其它一些控制符号一一对应，形成了ASCII (American Standard Code for Information Interchange)字符集。ASCII收录了128个字符，它们的代码就是对应的二进制数0000 0000 - 0111 1111，可以发现ASCII只占用了一个字节的后面7位，最前面的1位都是0。

## MBCS

计算机技术传播到非英语国家后，ASCII就无法满足需求了。开始的时候，一些国家采用一个字节里没有利用的0、1组合与一些字母和符号对应，形成了包括1000 0000 - 1111 1111的“扩展字符集”代码。但是，这还是远远不够，于是，每种语言都开始重新制定自己的字符集，由于单字节能表示的字符太少，这些字符集不约而同使用多字节来表示字符，如GBxxx、BIGxxx等DBCS (Double Byte Charecter Set)编码采用了两个字节，他们的规则是，如果第一个字节小于等于0111 1111，则仍然表示ASCII字符；而如果大于等于1000 0000，则跟下一个字节一起共16位表示一个字符。类似的方案被统称为MBCS(Multi-Byte Character Set)编码，IBM编了一个名为Code Page的索引，为这些字符集编码方案统一分配页码，GBK是第936页，因此GBK有时候也被记作CP936；Microsoft Windows根据计算机设定区域，调用不同的字符集，微软的程序员把他们这样的方案叫作ANSI，在简体中文Windows中，ANSI就是GBK。

GB2312字符集编码是1981年由中国发布的国家标准，采用两个大于等于1000 0000的字节连在一起表示一个字符，收录了6763个汉字以及拉丁字母、希腊字母、平假名、片假名、俄语西里尔字母等682个字符，GB2312还把ASCII里原有的数字、标点、字母按照自己的方案重新编成了两个字节即1xxx xxxx 1xxx xxxx的0、1组合，形成了“全角”字符。

GB2312字符集无法满足庞大的汉字字库的需求，于是，在兼容GB2312的基础上，Microsoft利用GB 2312方案第二个字节里小于0111 1111的编码空间，收录GB13000.1-93全部字符，制定了GBK字符集编码方案，即“汉字内码扩展规范”，GBK中的K就是汉语拼音Kuo Zhan的意思。GBK收录21886个汉字和图形符号，包括GB2312中的全部字符，以及繁体汉字、部首、符号。GBK被Microsoft用在了Windows 95中，成为广泛应用的汉字字符集编码方案。

GBK并不是国家标准，而是一种“技术规范指导性文件”，其依据的GB13000一直没有被业界接受，因此，后续的GB18030兼容了GB2312和GBK，但不包括GB13000。GB18030字符集将中国部分少数民族文字、日韩汉字、繁体汉字等等包括进来，采用了一二四字节可变长度编码方式，单字节(0000 0000 - 0111 1111)与ASCII编码兼容，双字节兼容GB2312，四字节形成了更大的编码空间。

BIG5字符集诞生于1983年，1992年5月发布了修订版本，BIG5通行于台湾、香港地区，采用了两个字节对繁体汉字进行编码，收录了13461个汉字和符号。

## unicode

这些编码五花八门，互不兼容，给程序员带来了不小的麻烦。ISO (国际标谁化组织)决定从零开始，对所有字符进行重新编码，这就是UCS (Universal Multiple-Octet Coded Character Set)，习惯被称为unicode字符集。unicode1.0发布于1991年10月，最新的unicode8.0发布于2015年6月17日。

UCS-2采用16位编码，即两个字节，UCS-4采用32位编码四个字节，对于一个字节就可以满足需求的英语文本来说，文件的体积至少大了一倍，空位浪费了存储空间，也不利于网络传输，因此，unicode在很长一段时间都没有推广开。

这时候，有些研究人员发现，字符集代码可以用另一种方式来传输和存储，他们制定了UTF (UCS Transfer Format)方案，对unicode的字符集代码进行重新编排，UTF-8以8位为一个单元，UTF-16以16位为一个单元。UTF-8伴随着互联网的兴起而得到了广泛应用。

UTF-8是一种长度变化的编码方式，使用1-4个字节表示一个字符。对于单字节的字符，字节的第一位设为0，后面7位就是该字符的unicode码，对于英语文本，UTF-8码和ASCII码相同；对于n个字节的符号(n>1)，第一个字节的前n位设为1，第n+1位设为0，后面字节的前两位一律设为10，其余空位为该字符的unicode码。

    0xxx xxxx
    110x xxxx 10xx xxxx
    1110 xxxx 10xx xxxx 10xx xxxx
    1111 0xxx 10xx xxxx 10xx xxxx 10xx xxxx

有些认主张区分字符集和编码，实际上，发布字符集就是为了规范字符编码，都有自己的编码对照表，在UTF-8诞生之前，几乎所有的编码方案都是直接采用了字符集的编码表；UTF-8首次区分了字符集编码表和字符的存储、传输编码，兼顾了代码的字符容量和编码的体积，使得文本的存储和传输效率大大提高。

## 编码检测

在python中，可以使用chardet对字符串、文件进行编码检测。

    >>> import chardet
    >>> f = open('test.txt')
    >>> s = f.read()
    >>> f.close()
    >>> chardet.detect(s)
    
## 编码与解码

    >>> u = u'中文编码'
    >>> s = u.encode('UTF-8')
    >>> u2 = s.decode('UTF-8')
    >>> print repr(u)
    u'\u4e2d\u6587\u7f16\u7801'
    >>> print repr(s)
    '\xe4\xb8\xad\xe6\x96\x87\xe7\xbc\x96\xe7\xa0\x81'
    >>> print repr(u2)
    u'\u4e2d\u6587\u7f16\u7801'
    >>> print str(s)
    中文编码
    
注意，下面几种情况会报错：

    >>> s2 = u.decode('UTF-8') #对unicode解码是错误的
    >>> u2 = s.encode('UTF-8') #对字符串编码是错误的
    >>> print str(u) #对unicode解码是错误的

`str()`返回的是给程序员看的字符串，`repr()`返回的是给计算机看的编码。

如果一个文件是GBK编码，可以通过下面的方法转成UTF-8编码。

    >>> f = open('gbk.txt')
    >>> s = f.read()
    >>> f.close
    >>> u = s.decode('GBK')
    >>> f = open('gbk.txt', 'w')
    >>> s = u.encode('UTF-8')
    >>> f.write(s)
    >>> f.close
















